# mamba-windows-cuda

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

<div align="center">

**[English](#english)** | **[ä¸­æ–‡](#ä¸­æ–‡)**

</div>

## English

### mamba-windows-cuda

Windows-compatible CUDA implementation of Mamba selective-scan operation, targeting **N=16** SSM (common Mamba configuration), supporting:

- FP16 / FP32
- `h_prev` as input final state (for streaming/chunking)
- `forward_with_state()` returns `h_last` (for chunked concatenation of ultra-long sequences)

The package performs **JIT compilation** of CUDA extensions locally via `torch.utils.cpp_extension.load_inline()`: initial import/first instantiation triggers compilation, subsequent use reuses cached artifacts.

### Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Requirements](#requirements)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Testing](#testing)
- [Performance](#performance)
- [Contributing](#contributing)
- [License](#license)

### Features

- âš¡ **Fast**: CUDA-accelerated selective scan operation for Mamba models
- ğŸ **Windows Support**: Full Windows compatibility with automatic MSVC environment setup
- ğŸ”§ **JIT Compilation**: On-the-fly compilation of CUDA kernels
- ğŸ§ª **Thoroughly Tested**: Comprehensive test coverage with numerical accuracy validation
- ğŸ“ **Flexible Shapes**: Support for various batch sizes, sequence lengths, and dimensions

### Requirements

- Python >= 3.9
- PyTorch with CUDA support
- NVIDIA CUDA Toolkit (for compilation)
- Visual Studio / Build Tools (MSVC) for Windows

### Installation

#### From Source

```bash
pip install -e .
```

#### From PyPI (if published)

```bash
pip install mamba-windows-cuda
```
æ³¨æ„ï¼šè¿™éœ€è¦é¡¹ç›®å·²ä½¿ç”¨åŒåå‘å¸ƒåˆ° PyPIã€‚
Note: this requires the project to be published to PyPI under the same name.

### Usage

#### Basic Usage

```python
import torch
from mamba_windows_cuda import SelectiveScanCuda

# Initialize the kernel
kernel = SelectiveScanCuda().cuda()

# Prepare input tensors
B, L, D, N = 1, 1024, 256, 16  # batch, length, dim, state

u = torch.randn(B, L, D, device='cuda').half()
delta = torch.ones(B, L, D, device='cuda').half()
A = (-torch.rand(D, N, device='cuda') * 0.1).half()
B_ssm = torch.randn(B, L, N, device='cuda').half()
C_ssm = torch.randn(B, L, N, device='cuda').half()
D_ssm = torch.ones(D, device='cuda').half()

# Basic forward pass
out = kernel(u, delta, A, B_ssm, C_ssm, D_ssm)

# Forward pass with state
out, h_last = kernel.forward_with_state(u, delta, A, B_ssm, C_ssm, D_ssm)
```

#### Streaming Usage (for long sequences)

```python
import torch
from mamba_windows_cuda import SelectiveScanCuda

kernel = SelectiveScanCuda().cuda()

# Initialize state
h = torch.zeros(1, 2048, 16, device='cuda').half()

# Process sequence in chunks
for chunk in sequence_chunks:
    out, h = kernel.forward_with_state(chunk['u'], chunk['delta'], 
                                      chunk['A'], chunk['B'], 
                                      chunk['C'], chunk['D'], h_prev=h)
```

### API Reference

#### `SelectiveScanCuda`

The main class implementing the CUDA-accelerated selective scan operation.

##### Methods

- `forward(u, delta, A, B_ssm, C_ssm, D_ssm, h_prev=None)`: Basic forward pass
- `forward_with_state(u, delta, A, B_ssm, C_ssm, D_ssm, h_prev=None)`: Forward pass returning state

##### Parameters

All parameters should be PyTorch tensors on CUDA device with `float16` or `float32` dtype.

- `u`: Input tensor of shape `(B, L, D)`
- `delta`: Delta tensor of shape `(B, L, D)`
- `A`: A matrix of shape `(D, 16)` (currently only N=16 is supported)
- `B_ssm`: B matrix of shape `(B, L, 16)`
- `C_ssm`: C matrix of shape `(B, L, 16)`
- `D_ssm`: D vector of shape `(D,)`
- `h_prev`: Optional initial hidden state of shape `(B, D, 16)`

##### Returns

- `forward()`: Output tensor of shape `(B, L, D)`
- `forward_with_state()`: Tuple of `(output_tensor, final_hidden_state)` where final_hidden_state is of shape `(B, D, 16)`

#### Tensor Shapes and Dtype Constraints

- `u`: `(B, L, D)`
- `delta`: `(B, L, D)`
- `A`: `(D, 16)` (currently only supports `N=16`)
- `B_ssm`: `(B, L, 16)`
- `C_ssm`: `(B, L, 16)`
- `D_ssm`: `(D,)`
- `h_prev` (optional): `(B, D, 16)`
- `out`: `(B, L, D)`
- `h_last` (optional return): `(B, D, 16)`

Dtype: `float16` or `float32`, and `u/delta/A/B_ssm/C_ssm/D_ssm/h_prev` must have the same dtype.

### Windows Compilation Dependencies

This package requires the ability to compile PyTorch CUDA extensions on Windows, which typically requires:

- PyTorch with CUDA installed (`torch.cuda.is_available()` returns `True`)
- NVIDIA CUDA Toolkit (for `nvcc` compiler)
- Visual Studio / Build Tools (MSVC)

The code attempts to automatically set up the MSVC environment variables via `vswhere.exe` + `VsDevCmd.bat` (see `mamba_windows_cuda/mamba_cuda.py`).

If you want to explicitly control the compilation target architecture, you can set:

- `TORCH_CUDA_ARCH_LIST` (e.g., `8.6`, `8.9`, etc.)

### Testing

```bash
python -m unittest -v mamba_windows_cuda.tests.test_selective_scan
```

#### Test Coverage

- FP16 numerical consistency with reference implementation (error threshold)
- Long sequences and extreme sizes: `L=16384/32768`, `D=768/1024/2048`
- Streaming for image feature sequences: `L=1280*1280`, `D=2048` (chunked concatenation with `h_last`)

### Performance

This implementation is optimized for Windows and provides efficient selective scan operations for Mamba models. It includes:

- Shared memory optimization for B and C matrices
- Warp-level primitives for efficient reductions
- Support for both FP16 and FP32 precision
- Optimized kernel launch parameters for different tensor sizes

### Contributing

Contributions are welcome! Here's how you can contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests if applicable
5. Ensure all tests pass (`python -m unittest -v mamba_windows_cuda.tests.test_selective_scan`)
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

Please make sure to update tests as appropriate and follow the existing code style.

### License

This repository is licensed under the MIT License. See [LICENSE](LICENSE).

### Acknowledgments

- The Mamba model and selective scan algorithm
- PyTorch for the CUDA extension framework
- The Windows PyTorch community for supporting CUDA development on Windows

---

## ä¸­æ–‡

### mamba-windows-cuda

é¢å‘ **N=16** çš„ SSMï¼ˆMamba å¸¸è§é…ç½®ï¼‰çš„ Windows å¯ç”¨ Mamba selective-scan CUDA å®ç°ï¼Œæ”¯æŒï¼š

- FP16 / FP32
- `h_prev` ä½œä¸ºè¾“å…¥æœ«æ€ï¼ˆç”¨äºæµå¼/åˆ†å—ï¼‰
- `forward_with_state()` è¿”å› `h_last`ï¼ˆç”¨äºè¶…é•¿åºåˆ—åˆ†å—ä¸²è”ï¼‰

è¯¥åŒ…é€šè¿‡ `torch.utils.cpp_extension.load_inline()` åœ¨æœ¬æœº **JIT ç¼–è¯‘** CUDA æ‰©å±•ï¼šé¦–æ¬¡å¯¼å…¥/é¦–æ¬¡å®ä¾‹åŒ–ä¼šè§¦å‘ç¼–è¯‘ï¼Œåç»­å¤ç”¨ç¼“å­˜äº§ç‰©ã€‚

### ç›®å½•

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [å®‰è£…](#å®‰è£…)
- [è¦æ±‚](#è¦æ±‚)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [API å‚è€ƒ](#api-å‚è€ƒ)
- [æµ‹è¯•](#æµ‹è¯•)
- [æ€§èƒ½](#æ€§èƒ½)
- [è´¡çŒ®](#è´¡çŒ®)
- [è®¸å¯è¯](#è®¸å¯è¯)

### åŠŸèƒ½ç‰¹æ€§

- âš¡ **å¿«é€Ÿ**: é’ˆå¯¹ Mamba æ¨¡å‹çš„ CUDA åŠ é€Ÿé€‰æ‹©æ€§æ‰«ææ“ä½œ
- ğŸ **Windows æ”¯æŒ**: å®Œå…¨å…¼å®¹ Windowsï¼Œè‡ªåŠ¨è®¾ç½® MSVC ç¯å¢ƒ
- ğŸ”§ **JIT ç¼–è¯‘**: å³æ—¶ç¼–è¯‘ CUDA å†…æ ¸
- ğŸ§ª **å…¨é¢æµ‹è¯•**: å…¨é¢çš„æµ‹è¯•è¦†ç›–ï¼ŒåŒ…å«æ•°å€¼ç²¾åº¦éªŒè¯
- ğŸ“ **çµæ´»å½¢çŠ¶**: æ”¯æŒå„ç§æ‰¹æ¬¡å¤§å°ã€åºåˆ—é•¿åº¦å’Œç»´åº¦

### è¦æ±‚

- Python >= 3.9
- æ”¯æŒ CUDA çš„ PyTorch
- NVIDIA CUDA Toolkitï¼ˆç”¨äºç¼–è¯‘ï¼‰
- Visual Studio / Build Toolsï¼ˆWindows ä¸Šçš„ MSVCï¼‰

### å®‰è£…

#### ä»æºç å®‰è£…

```bash
pip install -e .
```

#### ç›´æ¥å®‰è£…

```bash
pip install mamba-windows-cuda
```

### ä½¿ç”¨æ–¹æ³•

#### åŸºæœ¬ç”¨æ³•

```python
import torch
from mamba_windows_cuda import SelectiveScanCuda

# åˆå§‹åŒ–å†…æ ¸
kernel = SelectiveScanCuda().cuda()

# å‡†å¤‡è¾“å…¥å¼ é‡
B, L, D, N = 1, 1024, 256, 16  # æ‰¹æ¬¡ã€é•¿åº¦ã€ç»´åº¦ã€çŠ¶æ€

u = torch.randn(B, L, D, device='cuda').half()
delta = torch.ones(B, L, D, device='cuda').half()
A = (-torch.rand(D, N, device='cuda') * 0.1).half()
B_ssm = torch.randn(B, L, N, device='cuda').half()
C_ssm = torch.randn(B, L, N, device='cuda').half()
D_ssm = torch.ones(D, device='cuda').half()

# åŸºæœ¬å‰å‘ä¼ é€’
out = kernel(u, delta, A, B_ssm, C_ssm, D_ssm)

# å¸¦çŠ¶æ€çš„å‰å‘ä¼ é€’
out, h_last = kernel.forward_with_state(u, delta, A, B_ssm, C_ssm, D_ssm)
```

#### æµå¼ä½¿ç”¨ï¼ˆç”¨äºé•¿åºåˆ—ï¼‰

```python
import torch
from mamba_windows_cuda import SelectiveScanCuda

kernel = SelectiveScanCuda().cuda()

# åˆå§‹åŒ–çŠ¶æ€
h = torch.zeros(1, 2048, 16, device='cuda').half()

# åˆ†å—å¤„ç†åºåˆ—
for chunk in sequence_chunks:
    out, h = kernel.forward_with_state(chunk['u'], chunk['delta'], 
                                      chunk['A'], chunk['B'], 
                                      chunk['C'], chunk['D'], h_prev=h)
```

### API å‚è€ƒ

#### `SelectiveScanCuda`

å®ç° CUDA åŠ é€Ÿé€‰æ‹©æ€§æ‰«ææ“ä½œçš„ä¸»è¦ç±»ã€‚

##### æ–¹æ³•

- `forward(u, delta, A, B_ssm, C_ssm, D_ssm, h_prev=None)`: åŸºæœ¬å‰å‘ä¼ é€’
- `forward_with_state(u, delta, A, B_ssm, C_ssm, D_ssm, h_prev=None)`: è¿”å›çŠ¶æ€çš„å‰å‘ä¼ é€’

##### å‚æ•°

æ‰€æœ‰å‚æ•°éƒ½åº”è¯¥æ˜¯ CUDA è®¾å¤‡ä¸Šçš„ PyTorch å¼ é‡ï¼Œdtype ä¸º `float16` æˆ– `float32`ã€‚

- `u`: å½¢çŠ¶ä¸º `(B, L, D)` çš„è¾“å…¥å¼ é‡
- `delta`: å½¢çŠ¶ä¸º `(B, L, D)` çš„ Delta å¼ é‡
- `A`: å½¢çŠ¶ä¸º `(D, 16)` çš„ A çŸ©é˜µï¼ˆç›®å‰ä»…æ”¯æŒ N=16ï¼‰
- `B_ssm`: å½¢çŠ¶ä¸º `(B, L, 16)` çš„ B çŸ©é˜µ
- `C_ssm`: å½¢çŠ¶ä¸º `(B, L, 16)` çš„ C çŸ©é˜µ
- `D_ssm`: å½¢çŠ¶ä¸º `(D,)` çš„ D å‘é‡
- `h_prev`: å½¢çŠ¶ä¸º `(B, D, 16)` çš„å¯é€‰åˆå§‹éšè—çŠ¶æ€

##### è¿”å›å€¼

- `forward()`: å½¢çŠ¶ä¸º `(B, L, D)` çš„è¾“å‡ºå¼ é‡
- `forward_with_state()`: `(output_tensor, final_hidden_state)` çš„å…ƒç»„ï¼Œå…¶ä¸­ final_hidden_state å½¢çŠ¶ä¸º `(B, D, 16)`

#### å¼ é‡å½¢çŠ¶å’Œ Dtype çº¦æŸ

- `u`: `(B, L, D)`
- `delta`: `(B, L, D)`
- `A`: `(D, 16)`ï¼ˆç›®å‰ä»…æ”¯æŒ `N=16`ï¼‰
- `B_ssm`: `(B, L, 16)`
- `C_ssm`: `(B, L, 16)`
- `D_ssm`: `(D,)`
- `h_prev`ï¼ˆå¯é€‰ï¼‰: `(B, D, 16)`
- `out`: `(B, L, D)`
- `h_last`ï¼ˆå¯é€‰è¿”å›ï¼‰: `(B, D, 16)`

Dtype: `float16` æˆ– `float32`ï¼Œä¸” `u/delta/A/B_ssm/C_ssm/D_ssm/h_prev` å¿…é¡»å…·æœ‰ç›¸åŒçš„ dtypeã€‚

### Windows ç¼–è¯‘ä¾èµ–

æ­¤åŒ…éœ€è¦èƒ½å¤Ÿåœ¨ Windows ä¸Šç¼–è¯‘ PyTorch CUDA æ‰©å±•ï¼Œé€šå¸¸éœ€è¦ï¼š

- å®‰è£…äº† CUDA çš„ PyTorchï¼ˆ`torch.cuda.is_available()` è¿”å› `True`ï¼‰
- NVIDIA CUDA Toolkitï¼ˆç”¨äº `nvcc` ç¼–è¯‘å™¨ï¼‰
- Visual Studio / Build Toolsï¼ˆMSVCï¼‰

ä»£ç å°è¯•é€šè¿‡ `vswhere.exe` + `VsDevCmd.bat` è‡ªåŠ¨è®¾ç½® MSVC ç¯å¢ƒå˜é‡ï¼ˆå‚è§ `mamba_windows_cuda/mamba_cuda.py`ï¼‰ã€‚

å¦‚æœè¦æ˜¾å¼æ§åˆ¶ç¼–è¯‘ç›®æ ‡æ¶æ„ï¼Œå¯ä»¥è®¾ç½®ï¼š

- `TORCH_CUDA_ARCH_LIST`ï¼ˆä¾‹å¦‚ `8.6`ã€`8.9` ç­‰ï¼‰

### æµ‹è¯•

```bash
python -m unittest -v mamba_windows_cuda.tests.test_selective_scan
```

#### æµ‹è¯•è¦†ç›–

- ä¸å‚è€ƒå®ç°çš„ FP16 æ•°å€¼ä¸€è‡´æ€§ï¼ˆè¯¯å·®é˜ˆå€¼ï¼‰
- é•¿åºåˆ—å’Œæé™å°ºå¯¸ï¼š`L=16384/32768`ï¼Œ`D=768/1024/2048`
- å›¾åƒç‰¹å¾åºåˆ—æµå¼å¤„ç†ï¼š`L=1280*1280`ï¼Œ`D=2048`ï¼ˆä½¿ç”¨ `h_last` çš„åˆ†å—ä¸²è”ï¼‰

### æ€§èƒ½

æ­¤å®ç°åœ¨ Windows ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä¸º Mamba æ¨¡å‹æä¾›é«˜æ•ˆçš„é€‰æ‹©æ€§æ‰«ææ“ä½œã€‚å®ƒåŒ…æ‹¬ï¼š

- B å’Œ C çŸ©é˜µçš„å…±äº«å†…å­˜ä¼˜åŒ–
- ç”¨äºé«˜æ•ˆå½’çº¦çš„ Warp çº§åŸè¯­
- æ”¯æŒ FP16 å’Œ FP32 ç²¾åº¦
- é’ˆå¯¹ä¸åŒå¼ é‡å°ºå¯¸ä¼˜åŒ–çš„å†…æ ¸å¯åŠ¨å‚æ•°

### è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼ä»¥ä¸‹æ˜¯è´¡çŒ®æ–¹å¼ï¼š

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. è¿›è¡Œä¿®æ”¹
4. å¦‚é€‚ç”¨ï¼Œæ·»åŠ æµ‹è¯•
5. ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡ (`python -m unittest -v mamba_windows_cuda.tests.test_selective_scan`)
6. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
7. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
8. åˆ›å»º Pull Request

è¯·ç¡®ä¿é€‚å½“æ›´æ–°æµ‹è¯•å¹¶éµå¾ªç°æœ‰çš„ä»£ç é£æ ¼ã€‚

### è®¸å¯è¯

æœ¬ä»“åº“ä½¿ç”¨ MIT è®¸å¯è¯æˆæƒï¼Œè¯¦è§ [LICENSE](LICENSE)ã€‚

### è‡´è°¢

- Mamba æ¨¡å‹å’Œé€‰æ‹©æ€§æ‰«æç®—æ³•
- PyTorch çš„ CUDA æ‰©å±•æ¡†æ¶
- æ”¯æŒ Windows ä¸Š CUDA å¼€å‘çš„ Windows PyTorch ç¤¾åŒº
